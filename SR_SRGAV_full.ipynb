{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPklno4xyJ9mJ7+KYxpDksB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marina-Liu/3D-GAN-superresolution/blob/master/SR_SRGAV_full.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuSHDfkHRBde",
        "outputId": "73f219e1-55de-41f9-82d7-f240eae2f058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Super_resolution/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tJsebl3RViu",
        "outputId": "f8a78608-7793-4b8b-830a-b44adb0dc6a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Super_resolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/Marina-Liu/3D-GAN-superresolution.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlPKWSBgRcQG",
        "outputId": "0438b64a-0c9e-4501-a1f2-d05db07e382c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '3D-GAN-superresolution'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Total 53 (delta 0), reused 0 (delta 0), pack-reused 53\u001b[K\n",
            "Receiving objects: 100% (53/53), 133.56 KiB | 5.56 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd 3D-GAN-superresolution/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLFi6lUeSPWC",
        "outputId": "7e47d97d-b678-46a8-ed11-f9a2ecd6cf8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Super_resolution/3D-GAN-superresolution\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJH7kWS_TW-j",
        "outputId": "5b7e6443-3501-423d-99fe-b981f5165098"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorlayer\n",
            "  Downloading tensorlayer-2.2.5-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.2/381.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (2.31.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (1.23.5)\n",
            "Requirement already satisfied: progressbar2>=3.39.3 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (0.19.3)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (1.10.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (3.9.0)\n",
            "Requirement already satisfied: cloudpickle>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from tensorlayer) (2.2.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.5.0->tensorlayer) (9.4.0)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2>=3.39.3->tensorlayer) (3.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->tensorlayer) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->tensorlayer) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->tensorlayer) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->tensorlayer) (2023.7.22)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->tensorlayer) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->tensorlayer) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->tensorlayer) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15.0->tensorlayer) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.0->tensorlayer) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.0->tensorlayer) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2>=3.39.3->tensorlayer) (4.7.1)\n",
            "Installing collected packages: tensorlayer\n",
            "Successfully installed tensorlayer-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "from tensorlayer.layers import *\n",
        "from dataset import Train_dataset\n",
        "import math\n",
        "from scipy.ndimage import zoom        #\n",
        "from scipy.ndimage import gaussian_filter   #\n",
        "from utils import smooth_gan_labels, aggregate, subPixelConv3d\n",
        "import nibabel as nib\n",
        "import os\n",
        "from skimage.metrics import structural_similarity as ssim   #\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr   #\n",
        "from keras.layers.convolutional import UpSampling3D\n",
        "import argparse\n"
      ],
      "metadata": {
        "id": "oHlNeBy-T8gj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lrelu1(x):\n",
        "    return tf.maximum(x, 0.25 * x)\n",
        "\n",
        "\n",
        "def lrelu2(x):\n",
        "    return tf.maximum(x, 0.3 * x)\n",
        "\n",
        "\n",
        "def discriminator(input_disc, kernel, reuse, is_train=True):\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
        "    batch_size = 1\n",
        "    div_patches = 4\n",
        "    num_patches = 8\n",
        "    img_width = 128\n",
        "    img_height = 128\n",
        "    img_depth = 92\n",
        "    with tf.variable_scope(\"SRGAN_d\", reuse=reuse):\n",
        "        tl.layers.set_name_reuse(reuse)\n",
        "        input_disc.set_shape([int((batch_size * num_patches) / div_patches), img_width, img_height, img_depth, 1], )\n",
        "        x = InputLayer(input_disc, name='in')\n",
        "        x = Conv3dLayer(x, act=lrelu2, shape=[kernel, kernel, kernel, 1, 32], strides=[1, 1, 1, 1, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv1')\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 32, 32], strides=[1, 2, 2, 2, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv2')\n",
        "\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv2', act=lrelu2)\n",
        "\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 32, 64], strides=[1, 1, 1, 1, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv3')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv3', act=lrelu2)\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 64, 64], strides=[1, 2, 2, 2, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv4')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv4', act=lrelu2)\n",
        "\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 64, 128], strides=[1, 1, 1, 1, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv5')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv5', act=lrelu2)\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 128, 128], strides=[1, 2, 2, 2, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv6')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv6', act=lrelu2)\n",
        "\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 128, 256], strides=[1, 1, 1, 1, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv7')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv7', act=lrelu2)\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 256, 256], strides=[1, 2, 2, 2, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv8')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN1-conv8', act=lrelu2)\n",
        "\n",
        "        x = FlattenLayer(x, name='flatten')\n",
        "        x = DenseLayer(x, n_units=1024, act=lrelu2, name='dense1')\n",
        "        x = DenseLayer(x, n_units=1, name='dense2')\n",
        "\n",
        "        logits = x.outputs\n",
        "        x.outputs = tf.nn.sigmoid(x.outputs, name='output')\n",
        "\n",
        "        return x, logits\n",
        "\n",
        "\n",
        "def generator(input_gen, kernel, nb, upscaling_factor, reuse, feature_size, img_width, img_height, img_depth,\n",
        "              subpixel_NN, nn, is_train=True):\n",
        "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
        "\n",
        "    w_init_subpixel1 = np.random.normal(scale=0.02, size=[3, 3, 3, 64, feature_size])\n",
        "    w_init_subpixel1 = zoom(w_init_subpixel1, [2, 2, 2, 1, 1], order=0)\n",
        "    w_init_subpixel1_last = tf.constant_initializer(w_init_subpixel1)\n",
        "    w_init_subpixel2 = np.random.normal(scale=0.02, size=[3, 3, 3, 64, 64])\n",
        "    w_init_subpixel2 = zoom(w_init_subpixel2, [2, 2, 2, 1, 1], order=0)\n",
        "    w_init_subpixel2_last = tf.constant_initializer(w_init_subpixel2)\n",
        "\n",
        "    with tf.variable_scope(\"SRGAN_g\", reuse=reuse):\n",
        "        tl.layers.set_name_reuse(reuse)\n",
        "        x = InputLayer(input_gen, name='in')\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 1, feature_size], strides=[1, 1, 1, 1, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv1')\n",
        "        x = BatchNormLayer(x, act=lrelu1, is_train=is_train, name='BN-conv1')\n",
        "        inputRB = x\n",
        "        inputadd = x\n",
        "\n",
        "        # residual blocks\n",
        "        for i in range(nb):\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, feature_size, feature_size], strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='conv1-rb/%s' % i)\n",
        "            x = BatchNormLayer(x, act=lrelu1, is_train=is_train, name='BN1-rb/%s' % i)\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, feature_size, feature_size], strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='conv2-rb/%s' % i)\n",
        "            x = BatchNormLayer(x, is_train=is_train, name='BN2-rb/%s' % i, )\n",
        "            # short skip connection\n",
        "            x = ElementwiseLayer([x, inputadd], tf.add, name='add-rb/%s' % i)\n",
        "            inputadd = x\n",
        "\n",
        "        # large skip connection\n",
        "        x = Conv3dLayer(x, shape=[kernel, kernel, kernel, feature_size, feature_size], strides=[1, 1, 1, 1, 1],\n",
        "                        padding='SAME', W_init=w_init, name='conv2')\n",
        "        x = BatchNormLayer(x, is_train=is_train, name='BN-conv2')\n",
        "        x = ElementwiseLayer([x, inputRB], tf.add, name='add-conv2')\n",
        "\n",
        "        # ____________SUBPIXEL-NN______________#\n",
        "\n",
        "        if subpixel_NN:\n",
        "            # upscaling block 1\n",
        "            if upscaling_factor == 4:\n",
        "                img_height_deconv = int(img_height / 2)\n",
        "                img_width_deconv = int(img_width / 2)\n",
        "                img_depth_deconv = int(img_depth / 2)\n",
        "            else:\n",
        "                img_height_deconv = img_height\n",
        "                img_width_deconv = img_width\n",
        "                img_depth_deconv = img_depth\n",
        "\n",
        "            x = DeConv3dLayer(x, shape=[kernel * 2, kernel * 2, kernel * 2, 64, feature_size],\n",
        "                              act=lrelu1, strides=[1, 2, 2, 2, 1],\n",
        "                              output_shape=[tf.shape(input_gen)[0], img_height_deconv, img_width_deconv,\n",
        "                                            img_depth_deconv, 64],\n",
        "                              padding='SAME', W_init=w_init_subpixel1_last, name='conv1-ub-subpixelnn/1')\n",
        "\n",
        "            # upscaling block 2\n",
        "            if upscaling_factor == 4:\n",
        "                x = DeConv3dLayer(x, shape=[kernel * 2, kernel * 2, kernel * 2, 64, 64],\n",
        "                                  act=lrelu1, strides=[1, 2, 2, 2, 1], padding='SAME',\n",
        "                                  output_shape=[tf.shape(input_gen)[0], img_height, img_width,\n",
        "                                                img_depth, 64],\n",
        "                                  W_init=w_init_subpixel2_last, name='conv1-ub-subpixelnn/2')\n",
        "\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 64, 1], strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='convlast-subpixelnn')\n",
        "\n",
        "        # ____________RC______________#\n",
        "\n",
        "        elif nn:\n",
        "            # upscaling block 1\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, feature_size, 64], act=lrelu1,\n",
        "                            strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='conv1-ub/1')\n",
        "            x = UpSampling3D(name='UpSampling3D_1')(x.outputs)\n",
        "            x = Conv3dLayer(InputLayer(x, name='in ub1 conv2'),\n",
        "                            shape=[kernel, kernel, kernel, 64, 64],\n",
        "                            act=lrelu1,\n",
        "                            strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='conv2-ub/1')\n",
        "\n",
        "            # upscaling block 2\n",
        "            if upscaling_factor == 4:\n",
        "                x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 64, 64], act=lrelu1,\n",
        "                                strides=[1, 1, 1, 1, 1],\n",
        "                                padding='SAME', W_init=w_init, name='conv1-ub/2')\n",
        "                x = UpSampling3D(name='UpSampling3D_1')(x.outputs)\n",
        "                x = Conv3dLayer(InputLayer(x, name='in ub2 conv2'), shape=[kernel, kernel, kernel, 64,\n",
        "                                                                           64], act=lrelu1,\n",
        "                                strides=[1, 1, 1, 1, 1],\n",
        "                                padding='SAME', W_init=w_init, name='conv2-ub/2')\n",
        "\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, 64, 1], strides=[1, 1, 1, 1, 1],\n",
        "                            act=tf.nn.tanh, padding='SAME', W_init=w_init, name='convlast')\n",
        "\n",
        "        # ____________SUBPIXEL - BASELINE______________#\n",
        "\n",
        "        else:\n",
        "\n",
        "            if upscaling_factor == 4:\n",
        "                steps_to_end = 2\n",
        "            else:\n",
        "                steps_to_end = 1\n",
        "\n",
        "            # upscaling block 1\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, feature_size, 64], act=lrelu1,\n",
        "                            strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='conv1-ub/1')\n",
        "            arguments = {'img_width': img_width, 'img_height': img_height, 'img_depth': img_depth,\n",
        "                         'stepsToEnd': steps_to_end,\n",
        "                         'n_out_channel': int(64 / 8)}\n",
        "            x = LambdaLayer(x, fn=subPixelConv3d, fn_args=arguments, name='SubPixel1')\n",
        "\n",
        "            # upscaling block 2\n",
        "            if upscaling_factor == 4:\n",
        "                x = Conv3dLayer(x, shape=[kernel, kernel, kernel, int((64) / 8), 64], act=lrelu1,\n",
        "                                strides=[1, 1, 1, 1, 1],\n",
        "                                padding='SAME', W_init=w_init, name='conv1-ub/2')\n",
        "                arguments = {'img_width': img_width, 'img_height': img_height, 'img_depth': img_depth, 'stepsToEnd': 1,\n",
        "                             'n_out_channel': int(64 / 8)}\n",
        "                x = LambdaLayer(x, fn=subPixelConv3d, fn_args=arguments, name='SubPixel2')\n",
        "\n",
        "            x = Conv3dLayer(x, shape=[kernel, kernel, kernel, int(64 / 8), 1], strides=[1, 1, 1, 1, 1],\n",
        "                            padding='SAME', W_init=w_init, name='convlast')\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(upscaling_factor, residual_blocks, feature_size, path_prediction, checkpoint_dir, img_width, img_height,\n",
        "          img_depth, subpixel_NN, nn, restore, batch_size=1, div_patches=4, epochs=10):\n",
        "    traindataset = Train_dataset(batch_size)\n",
        "    iterations_train = math.ceil((len(traindataset.subject_list) * 0.8) / batch_size)\n",
        "    num_patches = traindataset.num_patches\n",
        "\n",
        "    # ##========================== DEFINE MODEL ============================##\n",
        "    t_input_gen = tf.placeholder('float32', [int((batch_size * num_patches) / div_patches), None,\n",
        "                                             None, None, 1],\n",
        "                                 name='t_image_input_to_SRGAN_generator')\n",
        "    t_target_image = tf.placeholder('float32', [int((batch_size * num_patches) / div_patches),\n",
        "                                                img_width, img_height, img_depth, 1],\n",
        "                                    name='t_target_image')\n",
        "    t_input_mask = tf.placeholder('float32', [int((batch_size * num_patches) / div_patches),\n",
        "                                              img_width, img_height, img_depth, 1],\n",
        "                                  name='t_image_input_mask')\n",
        "\n",
        "    net_gen = generator(input_gen=t_input_gen, kernel=3, nb=residual_blocks, upscaling_factor=upscaling_factor,\n",
        "                        img_height=img_height, img_width=img_width, img_depth=img_depth, subpixel_NN=subpixel_NN, nn=nn,\n",
        "                        feature_size=feature_size, is_train=True, reuse=False)\n",
        "    net_d, disc_out_real = discriminator(input_disc=t_target_image, kernel=3, is_train=True, reuse=False)\n",
        "    _, disc_out_fake = discriminator(input_disc=net_gen.outputs, kernel=3, is_train=True, reuse=True)\n",
        "\n",
        "    # test\n",
        "    gen_test = generator(t_input_gen, kernel=3, nb=residual_blocks, upscaling_factor=upscaling_factor,\n",
        "                         img_height=img_height, img_width=img_width, img_depth=img_depth, subpixel_NN=subpixel_NN,\n",
        "                         nn=nn,\n",
        "                         feature_size=feature_size, is_train=True, reuse=True)\n",
        "\n",
        "    # ###========================== DEFINE TRAIN OPS ==========================###\n",
        "\n",
        "    if np.random.uniform() > 0.1:\n",
        "        # give correct classifications\n",
        "        y_gan_real = tf.ones_like(disc_out_real)\n",
        "        y_gan_fake = tf.zeros_like(disc_out_real)\n",
        "    else:\n",
        "        # give wrong classifications (noisy labels)\n",
        "        y_gan_real = tf.zeros_like(disc_out_real)\n",
        "        y_gan_fake = tf.ones_like(disc_out_real)\n",
        "\n",
        "    d_loss_real = tf.reduce_mean(tf.square(disc_out_real - smooth_gan_labels(y_gan_real)),\n",
        "                                 name='d_loss_real')\n",
        "    d_loss_fake = tf.reduce_mean(tf.square(disc_out_fake - smooth_gan_labels(y_gan_fake)),\n",
        "                                 name='d_loss_fake')\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    mse_loss = tf.reduce_sum(\n",
        "        tf.square(net_gen.outputs - t_target_image), axis=[0, 1, 2, 3, 4], name='g_loss_mse')\n",
        "\n",
        "    dx_real = t_target_image[:, 1:, :, :, :] - t_target_image[:, :-1, :, :, :]\n",
        "    dy_real = t_target_image[:, :, 1:, :, :] - t_target_image[:, :, :-1, :, :]\n",
        "    dz_real = t_target_image[:, :, :, 1:, :] - t_target_image[:, :, :, :-1, :]\n",
        "    dx_fake = net_gen.outputs[:, 1:, :, :, :] - net_gen.outputs[:, :-1, :, :, :]\n",
        "    dy_fake = net_gen.outputs[:, :, 1:, :, :] - net_gen.outputs[:, :, :-1, :, :]\n",
        "    dz_fake = net_gen.outputs[:, :, :, 1:, :] - net_gen.outputs[:, :, :, :-1, :]\n",
        "\n",
        "    gd_loss = tf.reduce_sum(tf.square(tf.abs(dx_real) - tf.abs(dx_fake))) + \\\n",
        "              tf.reduce_sum(tf.square(tf.abs(dy_real) - tf.abs(dy_fake))) + \\\n",
        "              tf.reduce_sum(tf.square(tf.abs(dz_real) - tf.abs(dz_fake)))\n",
        "\n",
        "    g_gan_loss = 10e-2 * tf.reduce_mean(tf.square(disc_out_fake - smooth_gan_labels(tf.ones_like(disc_out_real))),\n",
        "                                        name='g_loss_gan')\n",
        "\n",
        "    g_loss = mse_loss + g_gan_loss + gd_loss\n",
        "\n",
        "    g_vars = tl.layers.get_variables_with_name('SRGAN_g', True, True)\n",
        "    d_vars = tl.layers.get_variables_with_name('SRGAN_d', True, True)\n",
        "\n",
        "    with tf.variable_scope('learning_rate'):\n",
        "        lr_v = tf.Variable(1e-4, trainable=False)\n",
        "    global_step = tf.Variable(0, trainable=False)\n",
        "    decay_rate = 0.5\n",
        "    decay_steps = 4920  # every 2 epochs (more or less)\n",
        "    learning_rate = tf.train.inverse_time_decay(lr_v, global_step=global_step, decay_rate=decay_rate,\n",
        "                                                decay_steps=decay_steps)\n",
        "\n",
        "    # Optimizers\n",
        "    g_optim = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
        "    d_optim = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
        "\n",
        "    session = tf.Session()\n",
        "    tl.layers.initialize_global_variables(session)\n",
        "\n",
        "    step = 0\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    if restore is not None:\n",
        "        saver.restore(session, tf.train.latest_checkpoint(restore))\n",
        "        val_restore = 0 * epochs\n",
        "    else:\n",
        "        val_restore = 0\n",
        "\n",
        "    array_psnr = []\n",
        "    array_ssim = []\n",
        "\n",
        "    for j in range(val_restore, epochs + val_restore):\n",
        "        for i in range(0, iterations_train):\n",
        "            # ====================== LOAD DATA =========================== #\n",
        "            xt_total = traindataset.patches_true(i)\n",
        "            xm_total = traindataset.mask(i)\n",
        "            for k in range(0, div_patches):\n",
        "                print('{}'.format(k))\n",
        "                xt = xt_total[k * int((batch_size * num_patches) / div_patches):(int(\n",
        "                    (batch_size * num_patches) / div_patches) * k) + int(\n",
        "                    (batch_size * num_patches) / div_patches)]\n",
        "                xm = xm_total[k * int((batch_size * num_patches) / div_patches):(int(\n",
        "                    (batch_size * num_patches) / div_patches) * k) + int(\n",
        "                    (batch_size * num_patches) / div_patches)]\n",
        "\n",
        "                # NORMALIZING\n",
        "                for t in range(0, xt.shape[0]):\n",
        "                    normfactor = (np.amax(xt[t])) / 2\n",
        "                    if normfactor != 0:\n",
        "                        xt[t] = ((xt[t] - normfactor) / normfactor)\n",
        "\n",
        "                x_generator = gaussian_filter(xt, sigma=1)\n",
        "                x_generator = zoom(x_generator, [1, (1 / upscaling_factor), (1 / upscaling_factor),\n",
        "                                                 (1 / upscaling_factor), 1], prefilter=False, order=0)\n",
        "                xgenin = x_generator\n",
        "\n",
        "                # ========================= train SRGAN ========================= #\n",
        "                # update D\n",
        "                errd, _ = session.run([d_loss, d_optim], {t_target_image: xt, t_input_gen: xgenin})\n",
        "                # update G\n",
        "                errg, errmse, errgan, errgd, _ = session.run([g_loss, mse_loss, g_gan_loss, gd_loss, g_optim],\n",
        "                                                             {t_input_gen: xgenin, t_target_image: xt,\n",
        "                                                              t_input_mask: xm})\n",
        "                print(\n",
        "                    \"Epoch [%2d/%2d] [%4d/%4d] [%4d/%4d]: d_loss: %.8f g_loss: %.8f (mse: %.6f gdl: %.6f adv: %.6f)\" % (\n",
        "                        j, epochs + val_restore, i, iterations_train, k, div_patches - 1, errd, errg, errmse, errgd,\n",
        "                        errgan))\n",
        "\n",
        "                # ========================= evaluate & save model ========================= #\n",
        "\n",
        "                if k == 1 and i % 20 == 0:\n",
        "                    if j - val_restore == 0:\n",
        "                        x_true_img = xt[0]\n",
        "                        if normfactor != 0:\n",
        "                            x_true_img = ((x_true_img + 1) * normfactor)  # denormalize\n",
        "                        img_true = nib.Nifti1Image(x_true_img, np.eye(4))\n",
        "                        img_true.to_filename(\n",
        "                            os.path.join(path_prediction, str(j) + str(i) + 'true.nii.gz'))\n",
        "\n",
        "                        x_gen_img = xgenin[0]\n",
        "                        if normfactor != 0:\n",
        "                            x_gen_img = ((x_gen_img + 1) * normfactor)  # denormalize\n",
        "                        img_gen = nib.Nifti1Image(x_gen_img, np.eye(4))\n",
        "                        img_gen.to_filename(\n",
        "                            os.path.join(path_prediction, str(j) + str(i) + 'gen.nii.gz'))\n",
        "\n",
        "                    x_pred = session.run(gen_test.outputs, {t_input_gen: xgenin})\n",
        "                    x_pred_img = x_pred[0]\n",
        "                    if normfactor != 0:\n",
        "                        x_pred_img = ((x_pred_img + 1) * normfactor)  # denormalize\n",
        "                    img_pred = nib.Nifti1Image(x_pred_img, np.eye(4))\n",
        "                    img_pred.to_filename(\n",
        "                        os.path.join(path_prediction, str(j) + str(i) + '.nii.gz'))\n",
        "\n",
        "                    max_gen = np.amax(x_pred_img)\n",
        "                    max_real = np.amax(x_true_img)\n",
        "                    if max_gen > max_real:\n",
        "                        val_max = max_gen\n",
        "                    else:\n",
        "                        val_max = max_real\n",
        "                    min_gen = np.amin(x_pred_img)\n",
        "                    min_real = np.amin(x_true_img)\n",
        "                    if min_gen < min_real:\n",
        "                        val_min = min_gen\n",
        "                    else:\n",
        "                        val_min = min_real\n",
        "                    val_psnr = psnr(np.multiply(x_true_img, xm[0]), np.multiply(x_pred_img, xm[0]),\n",
        "                                    dynamic_range=val_max - val_min)\n",
        "                    val_ssim = ssim(np.multiply(x_true_img, xm[0]), np.multiply(x_pred_img, xm[0]),\n",
        "                                    dynamic_range=val_max - val_min, multichannel=True)\n",
        "\n",
        "        saver.save(sess=session, save_path=checkpoint_dir, global_step=step)\n",
        "        print(\"Saved step: [%2d]\" % step)\n",
        "        step = step + 1\n",
        "\n",
        "\n",
        "def evaluate(upsampling_factor, residual_blocks, feature_size, checkpoint_dir_restore, path_volumes, nn, subpixel_NN,\n",
        "             img_height, img_width, img_depth):\n",
        "    traindataset = Train_dataset(1)\n",
        "    iterations = math.ceil(\n",
        "        (len(traindataset.subject_list) * 0.2))\n",
        "    print(len(traindataset.subject_list))\n",
        "    print(iterations)\n",
        "    totalpsnr = 0\n",
        "    totalssim = 0\n",
        "    array_psnr = np.empty(iterations)\n",
        "    array_ssim = np.empty(iterations)\n",
        "    batch_size = 1\n",
        "    div_patches = 4\n",
        "    num_patches = traindataset.num_patches\n",
        "\n",
        "    # define model\n",
        "    t_input_gen = tf.placeholder('float32', [1, None, None, None, 1],\n",
        "                                 name='t_image_input_to_SRGAN_generator')\n",
        "    srgan_network = generator(input_gen=t_input_gen, kernel=3, nb=residual_blocks,\n",
        "                              upscaling_factor=upsampling_factor, feature_size=feature_size, subpixel_NN=subpixel_NN,\n",
        "                              img_height=img_height, img_width=img_width, img_depth=img_depth, nn=nn,\n",
        "                              is_train=False, reuse=False)\n",
        "\n",
        "    # restore g\n",
        "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
        "\n",
        "    saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"SRGAN_g\"))\n",
        "    saver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir_restore))\n",
        "\n",
        "    for i in range(0, iterations):\n",
        "        # extract volumes\n",
        "        xt_total = traindataset.data_true(654 + i)\n",
        "        xt_mask = traindataset.mask(654 + i)\n",
        "        normfactor = (np.amax(xt_total[0])) / 2\n",
        "        x_generator = ((xt_total[0] - normfactor) / normfactor)\n",
        "        res = 1 / upsampling_factor\n",
        "        x_generator = x_generator[:, :, :, np.newaxis]\n",
        "        x_generator = gaussian_filter(x_generator, sigma=1)\n",
        "        x_generator = zoom(x_generator, [res, res, res, 1], prefilter=False)\n",
        "        xg_generated = sess.run(srgan_network.outputs, {t_input_gen: x_generator[np.newaxis, :]})\n",
        "        xg_generated = ((xg_generated + 1) * normfactor)\n",
        "        volume_real = xt_total[0]\n",
        "        volume_real = volume_real[:, :, :, np.newaxis]\n",
        "        volume_generated = xg_generated[0]\n",
        "        volume_mask = aggregate(xt_mask)\n",
        "        # compute metrics\n",
        "        max_gen = np.amax(volume_generated)\n",
        "        max_real = np.amax(volume_real)\n",
        "        if max_gen > max_real:\n",
        "            val_max = max_gen\n",
        "        else:\n",
        "            val_max = max_real\n",
        "        min_gen = np.amin(volume_generated)\n",
        "        min_real = np.amin(volume_real)\n",
        "        if min_gen < min_real:\n",
        "            val_min = min_gen\n",
        "        else:\n",
        "            val_min = min_real\n",
        "        val_psnr = psnr(np.multiply(volume_real, volume_mask), np.multiply(volume_generated, volume_mask),\n",
        "                        dynamic_range=val_max - val_min)\n",
        "        array_psnr[i] = val_psnr\n",
        "\n",
        "        totalpsnr += val_psnr\n",
        "        val_ssim = ssim(np.multiply(volume_real, volume_mask), np.multiply(volume_generated, volume_mask),\n",
        "                        dynamic_range=val_max - val_min, multichannel=True)\n",
        "        array_ssim[i] = val_ssim\n",
        "        totalssim += val_ssim\n",
        "        print(val_psnr)\n",
        "        print(val_ssim)\n",
        "        # save volumes\n",
        "        filename_gen = os.path.join(path_volumes, str(i) + 'gen.nii.gz')\n",
        "        img_volume_gen = nib.Nifti1Image(volume_generated, np.eye(4))\n",
        "        img_volume_gen.to_filename(filename_gen)\n",
        "        filename_real = os.path.join(path_volumes, str(i) + 'real.nii.gz')\n",
        "        img_volume_real = nib.Nifti1Image(volume_real, np.eye(4))\n",
        "        img_volume_real.to_filename(filename_real)\n",
        "\n",
        "    print('{}{}'.format('PSNR: ', array_psnr))\n",
        "    print('{}{}'.format('SSIM: ', array_ssim))\n",
        "    print('{}{}'.format('Mean PSNR: ', array_psnr.mean()))\n",
        "    print('{}{}'.format('Mean SSIM: ', array_ssim.mean()))\n",
        "    print('{}{}'.format('Variance PSNR: ', array_psnr.var()))\n",
        "    print('{}{}'.format('Variance SSIM: ', array_ssim.var()))\n",
        "    print('{}{}'.format('Max PSNR: ', array_psnr.max()))\n",
        "    print('{}{}'.format('Min PSNR: ', array_psnr.min()))\n",
        "    print('{}{}'.format('Max SSIM: ', array_ssim.max()))\n",
        "    print('{}{}'.format('Min SSIM: ', array_ssim.min()))\n",
        "    print('{}{}'.format('Median PSNR: ', np.median(array_psnr)))\n",
        "    print('{}{}'.format('Median SSIM: ', np.median(array_ssim)))\n"
      ],
      "metadata": {
        "id": "l8ByujINSlKx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "E2kexdnlVSav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  parser = argparse.ArgumentParser(description='Predict script')\n",
        "  parser.add_argument('-path_prediction', help='Path to save training predictions')\n",
        "    parser.add_argument('-path_volumes', help='Path to save test volumes')\n",
        "  parser.add_argument('-checkpoint_dir', help='Path to save checkpoints')\n",
        "  parser.add_argument('-checkpoint_dir_restore', help='Path to restore checkpoints')\n",
        "  parser.add_argument('-residual_blocks', default=6, help='Number of residual blocks')\n",
        "  parser.add_argument('-upsampling_factor', default=4, help='Upsampling factor')\n",
        "  parser.add_argument('-evaluate', default=False, help='Test the model')\n",
        "  parser.add_argument('-subpixel_NN', default=False, help='Use subpixel nearest neighbour')\n",
        "  parser.add_argument('-nn', default=False, help='Use Upsampling3D + nearest neighbour, RC')\n",
        "  parser.add_argument('-feature_size', default=32, help='Number of filters')\n",
        "  parser.add_argument('-restore', default=None, help='Checkpoint path to restore training')\n",
        "  args = parser.parse_args()\n",
        "'''\n",
        "upsampling_factor = 2\n",
        "feature_size = 32\n",
        "subpixel_NN = True\n",
        "nn = False\n",
        "residual_blocks = 6\n",
        "\n",
        "path_prediction =\n",
        "checkpoint_dir =\n",
        "\n",
        "img_width = 128\n",
        "img_height = 128\n",
        "img_depth = 92\n",
        "batch_size = 1\n",
        "\n",
        "restore = None\n",
        "\n",
        "train(upscaling_factor=upsampling_factor, feature_size=feature_size,\n",
        "      subpixel_NN=subpixel_NN, nn=nn, residual_blocks=residual_blocks,\n",
        "      path_prediction=path_prediction, checkpoint_dir=checkpoint_dir, img_width=img_width,\n",
        "      img_height=img_height, img_depth=img_depth, batch_size=batch_size, restore=restore)"
      ],
      "metadata": {
        "id": "N7AnaVs5S8ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Predict script')\n",
        "    parser.add_argument('-path_prediction', help='Path to save training predictions')\n",
        "    parser.add_argument('-path_volumes', help='Path to save test volumes')\n",
        "    parser.add_argument('-checkpoint_dir', help='Path to save checkpoints')\n",
        "    parser.add_argument('-checkpoint_dir_restore', help='Path to restore checkpoints')\n",
        "    parser.add_argument('-residual_blocks', default=6, help='Number of residual blocks')\n",
        "    parser.add_argument('-upsampling_factor', default=4, help='Upsampling factor')\n",
        "    parser.add_argument('-evaluate', default=False, help='Test the model')\n",
        "    parser.add_argument('-subpixel_NN', default=False, help='Use subpixel nearest neighbour')\n",
        "    parser.add_argument('-nn', default=False, help='Use Upsampling3D + nearest neighbour, RC')\n",
        "    parser.add_argument('-feature_size', default=32, help='Number of filters')\n",
        "    parser.add_argument('-restore', default=None, help='Checkpoint path to restore training')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.evaluate:\n",
        "        evaluate(upsampling_factor=int(args.upsampling_factor), feature_size=int(args.feature_size),\n",
        "                 residual_blocks=int(args.residual_blocks), checkpoint_dir_restore=args.checkpoint_dir_restore,\n",
        "                 path_volumes=args.path_volumes, subpixel_NN=args.subpixel_NN, nn=args.nn, img_width=224,\n",
        "                 img_height=224, img_depth=152)\n",
        "    else:\n",
        "        train(upscaling_factor=int(args.upsampling_factor), feature_size=int(args.feature_size),\n",
        "              subpixel_NN=args.subpixel_NN, nn=args.nn, residual_blocks=int(args.residual_blocks),\n",
        "              path_prediction=args.path_prediction, checkpoint_dir=args.checkpoint_dir, img_width=128,\n",
        "              img_height=128, img_depth=92, batch_size=1, restore=args.restore)"
      ],
      "metadata": {
        "id": "AvWV05qDS6s5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}